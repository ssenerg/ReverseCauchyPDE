{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network approximations of Cauchy Inverse problem for linear PDEs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANNPDE.PDE import ReverseChauchyPDE\n",
    "from ANNPDE.PDE.shapes import (\n",
    "    ElipseShape, \n",
    "    CircleShape, \n",
    "    LineShape\n",
    ")\n",
    "from ANNPDE.ANN import (\n",
    "    LSTM,\n",
    "    prepare_data,\n",
    "    laplacian\n",
    ")\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = randint(1, 1000000)\n",
    "torch.manual_seed(SEED)\n",
    "print('Seed:', SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Cauchy Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_EXPR = 'E ** x1 * sin(x2) * cos(t)'\n",
    "G_EXPR = ['E ** x1 * sin(x2)', 'E ** x1 * cos(x2)']\n",
    "H_EXPR = 'E ** x1 * sin(x2)'\n",
    "Xs_symbol, t_symbol = ['x1', 'x2'], 't'\n",
    "\n",
    "print(\n",
    "    '\\n • ∂u(X, t)/∂t + Δu(X, t) = 0'\n",
    "    '\\n • u(X, t) = f =', F_EXPR,\n",
    "    '\\n • ∂u(X, t)/∂n = g =', G_EXPR,\n",
    "    '\\n • u(X, 0)  = h =', H_EXPR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_SAMPLE = 4\n",
    "E_SAMPLE = 32\n",
    "D_SAMPLE = 128\n",
    "CENTER = np.array([0, 0])\n",
    "RADIUS = 0.5\n",
    "EDGE_CUT = [(0, np.pi * .5), (np.pi * 1, np.pi * 1.5)]\n",
    "\n",
    "input_size = len(CENTER) + 1  # Input is (x1, x2, t)\n",
    "hidden_layer_sizes = [10, 20, 30]  # Customize your hidden layer sizes\n",
    "batch_size_divider = 64\n",
    "num_epochs = 5\n",
    "\n",
    "ec_lambda = lambda x: \"\\n    \".join(\n",
    "    [str(list(map(lambda x: round(x, 5), cut))) for cut in x]\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\nTraining parameters:'\n",
    "    '\\n • Time sample:', T_SAMPLE,\n",
    "    '\\n • Edge sample:', E_SAMPLE,\n",
    "    '\\n • Domain sample:', D_SAMPLE,\n",
    "    '\\n\\n • Circle Center:', CENTER,\n",
    "    '\\n • Circle Radius:', RADIUS,\n",
    "    f'\\n • Circle Edge Cut(s): [\\n    {ec_lambda(EDGE_CUT)}\\n  ]',\n",
    "    '\\n\\n • Hidden layer sizes:', hidden_layer_sizes,\n",
    "    '\\n • Batch Size Divider:',batch_size_divider, \n",
    "    '\\n • Batch size :', ((E_SAMPLE + D_SAMPLE) * T_SAMPLE) // batch_size_divider,\n",
    "    '=  (E_SAMPLE+D_SAMPLE)*T_SAMPLE)//batch_size_divider',\n",
    "    '\\n • Number of epochs:', num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = LineShape(\n",
    "    seed=SEED,\n",
    "    n=T_SAMPLE,\n",
    "    start_point=0,\n",
    "    end_point=np.pi/2,\n",
    "    cross_sample_generate=1,\n",
    "    even_sample=True\n",
    ")\n",
    "time_sample = time.get()\n",
    "\n",
    "time.plot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = CircleShape(\n",
    "    seed=SEED,\n",
    "    edge_n=E_SAMPLE,\n",
    "    domain_n=D_SAMPLE,\n",
    "    center=CENTER,\n",
    "    radius=RADIUS,\n",
    "    cross_sample_generate=1,\n",
    "    edge_cuts_angle=EDGE_CUT,\n",
    "    even_sample=True\n",
    ")\n",
    "edge_sample, domain_sample = shape.get()\n",
    "\n",
    "shape.plot(1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LSTM(input_size, hidden_layer_sizes)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "pde = ReverseChauchyPDE(\n",
    "    f_function=F_EXPR,\n",
    "    g_function=G_EXPR,\n",
    "    h_function=H_EXPR,\n",
    "    x_symbols=Xs_symbol,\n",
    "    time_symbol=t_symbol,\n",
    "    criterion=criterion\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "domain_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, domain_sample)\n",
    ").float()\n",
    "edge_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, edge_sample)\n",
    ").float()\n",
    "\n",
    "batch_size_edge = int(edge_input.shape[0] / batch_size_divider)\n",
    "batch_size_domain = int(domain_input.shape[0] / batch_size_divider)\n",
    "\n",
    "print(\n",
    "    '\\nSampling Information:'\n",
    "    '\\n • Domain input shape:', tuple(domain_input.shape),\n",
    "    '\\n • Edge input shape:', tuple(edge_input.shape),\n",
    "    '\\n • Domain Batch size:', batch_size_domain,\n",
    "    '\\n • Edge Batch size:', batch_size_edge\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = {\n",
    "    'epoch':      [],\n",
    "    \n",
    "    'tr_loss':    [],\n",
    "    'f_loss':     [],\n",
    "    'g_loss':     [],\n",
    "    'h_loss':     [],\n",
    "\n",
    "    'total_loss': [],\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    domain_input = domain_input[torch.randperm(domain_input.size()[0])]\n",
    "    edge_input = edge_input[torch.randperm(edge_input.size()[0])]   \n",
    "\n",
    "    for key, value in tracking.items():\n",
    "        if key == 'epoch':\n",
    "            value.append(epoch + 1)\n",
    "            continue\n",
    "        value.append(0.0)\n",
    "\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs} loop ...')\n",
    "    \n",
    "    for i in tqdm(range(batch_size_divider)):\n",
    "\n",
    "        batch_domain = domain_input[i*batch_size_domain:(i+1)*batch_size_domain, :]\n",
    "        batch_edge = edge_input[i*batch_size_edge:(i+1)*batch_size_edge, :]\n",
    "\n",
    "        inputs = torch.cat((batch_domain, batch_edge), dim=0)\n",
    "        inputs.requires_grad_(True)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculating the gradients\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True\n",
    "        )[0]\n",
    "        laplacians = laplacian(inputs, gradients)\n",
    "\n",
    "        # Calculate Loss\n",
    "        tr_loss, f_loss, g_loss, h_loss = pde.loss_function(\n",
    "            inputs,\n",
    "            batch_domain.size(0),\n",
    "            outputs,\n",
    "            gradients,\n",
    "            laplacians,\n",
    "            model,\n",
    "        )\n",
    "\n",
    "        combined_loss = tr_loss / inputs.size(0) + \\\n",
    "            f_loss / batch_edge.size(0) + \\\n",
    "                g_loss / batch_edge.size(0) + \\\n",
    "                    h_loss / inputs.size(0)\n",
    "                    \n",
    "        tracking['total_loss'][-1] += combined_loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tracking['tr_loss'][-1] += tr_loss.item()\n",
    "        tracking['f_loss'][-1] += f_loss.item()\n",
    "        tracking['g_loss'][-1] += g_loss.item()\n",
    "        tracking['h_loss'][-1] += h_loss.item()\n",
    "    \n",
    "    print(\n",
    "        'Epoch [{}/{}], Total Loss: {:.4f}\\nTR Loss: {:.4f}, F Loss: {:.4f}, ' \\\n",
    "        'G Loss: {:.4f}, H Loss: {:.4f}'.format(\n",
    "            epoch + 1, \n",
    "            num_epochs, \n",
    "            tracking['total_loss'][-1] / batch_size_divider,\n",
    "            tracking['tr_loss'][-1] / batch_size_divider, \n",
    "            tracking['f_loss'][-1] / batch_size_divider, \n",
    "            tracking['g_loss'][-1] / batch_size_divider, \n",
    "            tracking['h_loss'][-1] / batch_size_divider\n",
    "        )\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = pd.DataFrame(tracking)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tracking['epoch'], y=tracking['tr_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='TR Loss'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tracking['epoch'], y=tracking['f_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='F Loss'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tracking['epoch'], y=tracking['g_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='G Loss'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tracking['epoch'], y=tracking['h_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='H Loss'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=tracking['epoch'], y=tracking['total_loss'],\n",
    "    mode='lines+markers',\n",
    "    name='Total Loss'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='Losses',\n",
    "    xaxis_title='Epoch',\n",
    "    yaxis_title='Loss',\n",
    "    legend_title='Losses',\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = [np.pi/5, 3*np.pi/10, 2*np.pi/5, np.pi/2]\n",
    "precision = 100\n",
    "x_lin, y_lin, mesh_x, mesh_y, mask = shape.mesh(precision)\n",
    "stacked_grid = np.stack((mesh_x.flatten(), mesh_y.flatten()), axis=-1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(len(Ts)):\n",
    "        mesh_z = np.where(mask, 1, np.nan)\n",
    "        for x in range(precision):\n",
    "            for y in range(precision):\n",
    "                if mesh_z[x, y] != 1:\n",
    "                    continue\n",
    "                input_tensor = torch.tensor(np.array(\n",
    "                    np.array([x, y, Ts[i]]).reshape(1, 3)\n",
    "                ), dtype=torch.float32)\n",
    "\n",
    "                mesh_z[x, y] = model(input_tensor).squeeze()\n",
    "        \n",
    "        # Create the contour plot\n",
    "        contour = go.Contour(\n",
    "            x=x_lin,\n",
    "            y=y_lin,\n",
    "            z=mesh_z,\n",
    "            colorscale='RdBu',\n",
    "            ncontours=300,\n",
    "            showscale=True,\n",
    "            line=dict(width=0)\n",
    "        )\n",
    "\n",
    "\n",
    "        # Define layout to maintain aspect ratio\n",
    "        layout = go.Layout(\n",
    "            xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
    "            yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "            title=f\"T = {Ts[i]}\"\n",
    "        )\n",
    "\n",
    "        # Create the figure\n",
    "        fig = go.Figure(data=[contour], layout=layout)\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
