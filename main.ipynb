{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial neural network approximations of Cauchy inverse problem for linear PDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANNPDE.PDE import ReverseChauchyPDE\n",
    "from ANNPDE.PDE.shapes import (\n",
    "    ElipseShape, \n",
    "    CircleShape, \n",
    "    LineShape\n",
    ")\n",
    "from ANNPDE.ANN import (\n",
    "    LSTM,\n",
    "    prepare_data\n",
    ")\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = randint(1, 1000000)\n",
    "torch.manual_seed(SEED)\n",
    "print('Seed:', SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Cauchy Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_EXPR = 'E ** x1 * sin(x2) * cos(t)'\n",
    "G_EXPR = ['E ** x1 * sin(x2)', 'E ** x1 * cos(x2)']\n",
    "H_EXPR = 'E ** x1 * sin(x2)'\n",
    "Xs_symbol, t_symbol = ['x1', 'x2'], 't'\n",
    "\n",
    "print(\n",
    "    '\\n • ∂u(X, t)/∂t + Δu(X, t) = 0'\n",
    "    '\\n • u(X, t) = f =', F_EXPR,\n",
    "    '\\n • ∂u(X, t)/∂n = g =', G_EXPR,\n",
    "    '\\n • u(X, 0)  = h =', H_EXPR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_SAMPLE = 64\n",
    "E_SAMPLE = 128\n",
    "D_SAMPLE = 512\n",
    "CENTER = np.array([0, 0])\n",
    "RADIUS = 0.5\n",
    "EDGE_CUT = [(0, np.pi * .5), (np.pi * 1, np.pi * 1.5)]\n",
    "\n",
    "input_size = len(CENTER) + 1  # Input is (x1, x2, t)\n",
    "hidden_layer_sizes = [10, 20, 70, 30]  # Customize your hidden layer sizes\n",
    "batch_size_divider = 64\n",
    "num_epochs = 100\n",
    "\n",
    "ec_lambda = lambda x: \"\\n    \".join(\n",
    "    [str(list(map(lambda x: round(x, 5), cut))) for cut in x]\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\nTraining parameters:'\n",
    "    '\\n • Time sample:', T_SAMPLE,\n",
    "    '\\n • Edge sample:', E_SAMPLE,\n",
    "    '\\n • Domain sample:', D_SAMPLE,\n",
    "    '\\n\\n • Circle Center:', CENTER,\n",
    "    '\\n • Circle Radius:', RADIUS,\n",
    "    f'\\n • Circle Edge Cut(s): [\\n    {ec_lambda(EDGE_CUT)}\\n  ]',\n",
    "    '\\n\\n • Hidden layer sizes:', hidden_layer_sizes,\n",
    "    '\\n • Batch Size Divider:',batch_size_divider, \n",
    "    '\\n • Batch size :', ((E_SAMPLE + D_SAMPLE) * T_SAMPLE) // batch_size_divider,\n",
    "    '=  (E_SAMPLE+D_SAMPLE)*T_SAMPLE)//batch_size_divider',\n",
    "    '\\n • Number of epochs:', num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = LineShape(\n",
    "    seed=SEED,\n",
    "    n=T_SAMPLE,\n",
    "    start_point=0,\n",
    "    end_point=np.pi/2,\n",
    "    cross_sample_generate=1,\n",
    "    even_sample=True\n",
    ")\n",
    "time_sample = time.get()\n",
    "\n",
    "time.plot(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = CircleShape(\n",
    "    seed=SEED,\n",
    "    edge_n=E_SAMPLE,\n",
    "    domain_n=D_SAMPLE,\n",
    "    center=CENTER,\n",
    "    radius=RADIUS,\n",
    "    cross_sample_generate=1,\n",
    "    edge_cuts_angle=EDGE_CUT,\n",
    "    even_sample=True\n",
    ")\n",
    "edge_sample, domain_sample = shape.get()\n",
    "\n",
    "shape.plot(1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LSTM(input_size, hidden_layer_sizes)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "pde = ReverseChauchyPDE(\n",
    "    f_function=F_EXPR,\n",
    "    g_function=G_EXPR,\n",
    "    h_function=H_EXPR,\n",
    "    x_symbols=Xs_symbol,\n",
    "    time_symbol=t_symbol,\n",
    "    criterion=criterion\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "domain_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, domain_sample)\n",
    ").float()\n",
    "edge_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, edge_sample)\n",
    ").float()\n",
    "\n",
    "domain_input = domain_input[torch.randperm(domain_input.size()[0])]\n",
    "edge_input = edge_input[torch.randperm(edge_input.size()[0])]\n",
    "\n",
    "batch_size_edge = int(edge_input.shape[0] / batch_size_divider)\n",
    "batch_size_domain = int(domain_input.shape[0] / batch_size_divider)\n",
    "\n",
    "print(\n",
    "    '\\nSampling Information:'\n",
    "    '\\n • Domain input shape:', tuple(domain_input.shape),\n",
    "    '\\n • Edge input shape:', tuple(edge_input.shape),\n",
    "    '\\n • Domain Batch size:', batch_size_domain,\n",
    "    '\\n • Edge Batch size:', batch_size_edge\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_tr_loss = 0.0\n",
    "    total_f_loss = 0.0\n",
    "    total_g_loss = 0.0\n",
    "    total_h_loss = 0.0\n",
    "\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs} loop ...')\n",
    "    \n",
    "    for i in tqdm(range(batch_size_divider)):\n",
    "\n",
    "        batch_domain = domain_input[i*batch_size_domain:(i+1)*batch_size_domain, :]\n",
    "        batch_edge = edge_input[i*batch_size_edge:(i+1)*batch_size_edge, :]\n",
    "\n",
    "        inputs = torch.cat((batch_domain, batch_edge), dim=0)\n",
    "        inputs.requires_grad_(True)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "\n",
    "        # Calculating the gradients ----------------------------------------------------\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        # Calculate the laplacian ------------------------------------------------------\n",
    "\n",
    "        laplacians = torch.zeros(inputs.shape)\n",
    "\n",
    "        # Calculate the second derivatives for each input dimension\n",
    "        for k in range(inputs.shape[1]):\n",
    "            # Calculate the gradient of the gradients (second derivatives)\n",
    "            second_derivatives = torch.autograd.grad(\n",
    "                gradients[:, k], \n",
    "                inputs, \n",
    "                grad_outputs=torch.ones_like(gradients[:, k]), \n",
    "                create_graph=True\n",
    "            )[0]\n",
    "            # Extract the diagonal elements corresponding to the second derivative of \n",
    "            # each input\n",
    "            laplacians[:, k] = second_derivatives[:, k]\n",
    "\n",
    "        laplacians = torch.sum(laplacians ** 2, dim=1, keepdim=True)\n",
    "\n",
    "        # ------------------ Calculate Loss functions ----------------------------------\n",
    "        # Calculate the loss on the domain using laplacian function\n",
    "        tr_loss = criterion(\n",
    "            laplacians + gradients[:, -1].unsqueeze(1), torch.zeros(laplacians.shape)\n",
    "        )\n",
    "        # Calculate the loss on the Edge\n",
    "        f_loss = pde.loss(\n",
    "            'f', \n",
    "            outputs[batch_domain.size(0): ], \n",
    "            inputs[batch_domain.size(0): ]\n",
    "        )\n",
    "        # Calculate the loss on the boundary using the normal vector\n",
    "        g_loss = pde.loss(\n",
    "            'g', \n",
    "            inputs[batch_domain.size(0):], \n",
    "            gradients[batch_domain.size(0):, : -1]\n",
    "        )\n",
    "        # Calculate the loss on the boundary at t = 0\n",
    "        on_zero_input = torch.cat(\n",
    "            (inputs[:, :-1], torch.zeros((inputs.shape[0], 1))),\n",
    "            dim=1\n",
    "        )\n",
    "        on_zero_output = model(on_zero_input)\n",
    "        h_loss = pde.loss('h', on_zero_output, on_zero_input)\n",
    "        # ------------------------------------------------------------------------------\n",
    "\n",
    "        # Calculate the combined loss\n",
    "        combined_loss = tr_loss / inputs.size(0) + \\\n",
    "            f_loss / batch_edge.size(0) + \\\n",
    "                g_loss / batch_edge.size(0) + \\\n",
    "                    h_loss / inputs.size(0)\n",
    "        # Backward and optimize\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_tr_loss += tr_loss.item()\n",
    "        total_f_loss += f_loss.item()\n",
    "        total_g_loss += g_loss.item()\n",
    "        total_h_loss += h_loss.item()\n",
    "    \n",
    "    print(\n",
    "        'Epoch [{}/{}], TR Loss: {:.4f}, F Loss: {:.4f}, ' \\\n",
    "        'G Loss: {:.4f}, H Loss: {:.4f}'.format(\n",
    "            epoch+1, \n",
    "            num_epochs, \n",
    "            total_tr_loss / batch_size_divider, \n",
    "            total_f_loss / batch_size_divider, \n",
    "            total_g_loss / batch_size_divider, \n",
    "            total_h_loss / batch_size_divider\n",
    "        )\n",
    "    ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
