{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANNPDE.PDE import ReverseChauchyPDE\n",
    "from ANNPDE.PDE.shapes import (\n",
    "    ElipseShape, \n",
    "    CircleShape, \n",
    "    LineShape\n",
    ")\n",
    "from ANNPDE.ANN import (\n",
    "    LSTM, \n",
    "    laplacian,\n",
    "    derivative,\n",
    "    prepare_data\n",
    ")\n",
    "import plotly.graph_objs as go\n",
    "from random import randint\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else \\\n",
    "    torch.device(\"cpu\")\n",
    "\n",
    "SEED = randint(1, 1000000)\n",
    "print('Seed:', SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2  # Dimension of the surface\n",
    "input_size = n + 1  # Input is (x1, x2, t)\n",
    "hidden_layer_sizes = [10, 20, 50, 90, 150, 100, 50]  # Customize your hidden layer sizes\n",
    "output_size = 1  \n",
    "batch_size_divider = 512\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "print(\n",
    "      'Surface dimension: ', n, \n",
    "      '\\nHidden layer sizes: ', hidden_layer_sizes, \n",
    "      '\\nBatch size divider: ', batch_size_divider,\n",
    "      '\\nEpochs: ', num_epochs,\n",
    "      '\\n\\nInput size: ', input_size, \n",
    "      '\\nOutput size: ', output_size\n",
    ")\n",
    "\n",
    "\n",
    "F_EXPR = 'E ** x1 * sin(x2) * cos(t)'\n",
    "G_EXPR = ['E ** x1 * sin(x2)', 'E ** x1 * cos(x2)']\n",
    "H_EXPR = 'E ** x1 * sin(x2)'\n",
    "Xs_symbol, t_symbol = ['x1', 'x2'], 't'\n",
    "\n",
    "print()\n",
    "print('f(x1, x2, t) =', F_EXPR)\n",
    "print('g(x1, x2, t) =', G_EXPR)\n",
    "print('h(x1, x2, t) =', H_EXPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_SAMPLE = 512\n",
    "E_SAMPLE = 256\n",
    "D_SAMPLE = 2048\n",
    "CENTER = np.array([0, 0])\n",
    "RADIUS = 10\n",
    "\n",
    "print('Time sample:', T_SAMPLE)\n",
    "print('Edge sample:', E_SAMPLE)\n",
    "print('Domain sample:', D_SAMPLE)\n",
    "print('\\nCircle Center:', CENTER)\n",
    "print('Circle Radius:', RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = LineShape(\n",
    "    seed=SEED,\n",
    "    n=T_SAMPLE,\n",
    "    start_point=0,\n",
    "    end_point=np.pi/2,\n",
    "    cross_sample_generate=1,\n",
    "    even_sample=True\n",
    ")\n",
    "time_sample = time.get()\n",
    "\n",
    "print('Time sample shape:', time_sample.shape)\n",
    "time.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = CircleShape(\n",
    "    seed=SEED,\n",
    "    edge_n=E_SAMPLE,\n",
    "    domain_n=D_SAMPLE,\n",
    "    center=CENTER,\n",
    "    radius=RADIUS,\n",
    "    cross_sample_generate=1,\n",
    "    even_sample=True\n",
    ")\n",
    "edge_sample, domain_sample = shape.get()\n",
    "\n",
    "print('Edge sample shape:', edge_sample.shape)\n",
    "print('Domain sample shape:', domain_sample.shape)\n",
    "shape.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_layer_sizes, output_size)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "pde = ReverseChauchyPDE(\n",
    "    f_function=F_EXPR,\n",
    "    g_function=G_EXPR,\n",
    "    h_function=H_EXPR,\n",
    "    x_symbols=Xs_symbol,\n",
    "    time_symbol=t_symbol,\n",
    "    criterion=criterion\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, domain_sample)\n",
    ").float().to(device)\n",
    "edge_input = torch.from_numpy(\n",
    "    prepare_data(time_sample, edge_sample)\n",
    ").float().to(device)\n",
    "\n",
    "domain_input = domain_input[torch.randperm(domain_input.size()[0])]\n",
    "edge_input = edge_input[torch.randperm(edge_input.size()[0])]\n",
    "batch_size_edge = int(edge_input.shape[0] / batch_size_divider)\n",
    "batch_size_domain = int(domain_input.shape[0] / batch_size_divider)\n",
    "\n",
    "combined_data = torch.cat((domain_input, edge_input), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    total_tr_loss = 0.0\n",
    "    total_f_loss = 0.0\n",
    "    total_g_loss = 0.0\n",
    "    total_h_loss = 0.0\n",
    "    \n",
    "    for i in range(batch_size_divider):\n",
    "\n",
    "        batch_domain = domain_input[i*batch_size_domain:(i+1)*batch_size_domain, :].to(device)\n",
    "        batch_edge = edge_input[i*batch_size_edge:(i+1)*batch_size_edge, :].to(device)\n",
    "\n",
    "        inputs = torch.cat((batch_domain, batch_edge), dim=0).to(device)\n",
    "        print('Input size: ', inputs.shape)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        print('Output size: ', outputs.shape)\n",
    "\n",
    "        laplacian_ = laplacian(model, batch_domain).to(device)\n",
    "        gradient = derivative(model, inputs).to(device)\n",
    "\n",
    "        tr_loss = criterion(laplacian_ + gradient[:, -1], torch.zeros(laplacian_))\n",
    "        print('Laplacian Loss: ', tr_loss)\n",
    "\n",
    "        f_loss = pde.loss('f', outputs[batch_domain.size(0): ], gradient)\n",
    "        print('F Loss: ', f_loss)\n",
    "\n",
    "        g_loss = pde.loss('g', outputs[batch_domain.size(0): ], gradient) # TODO: DRICHLET O INA\n",
    "        print('G Loss: ', g_loss)\n",
    "\n",
    "        on_zero_input = torch.cat(\n",
    "            (batch_domain[:, :-1], torch.zeros((batch_domain.shape[0], 1))),\n",
    "            dim=1\n",
    "        )\n",
    "        on_zero_output = model(on_zero_input)\n",
    "        h_loss = pde.loss('h', on_zero_output, on_zero_input)\n",
    "        print('H Loss: ', h_loss)\n",
    "        \n",
    "\n",
    "        combined_loss = tr_loss / laplacian_.shape[0] + \\\n",
    "            f_loss / batch_edge.shape[0] + \\\n",
    "                g_loss / batch_edge.shape[0] + \\\n",
    "                    h_loss / batch_domain.shape[0]\n",
    "\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_tr_loss += tr_loss.item()\n",
    "        total_f_loss += f_loss.item()\n",
    "        total_g_loss += g_loss.item()\n",
    "        total_h_loss += h_loss.item()\n",
    "    \n",
    "    print(\n",
    "        'Epoch [{}/{}], TR Loss: {:.4f}, F Loss: {:.4f}, ' \\\n",
    "        'G Loss: {:.4f}, H Loss: {:.4f}'.format(\n",
    "            epoch+1, \n",
    "            num_epochs, \n",
    "            total_tr_loss/(i+1), \n",
    "            total_f_loss/(i+1), \n",
    "            total_g_loss/(i+1), \n",
    "            total_h_loss/(i+1)\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
